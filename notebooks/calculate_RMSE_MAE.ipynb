{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31651182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Define a function to interpolate missing time steps in a DataFrame \n",
    "def interpolate_missing_time_steps(df):\n",
    "    time_column = df.columns[0]  # Extract the time column name\n",
    "    probability_columns = df.columns[1:]  # Extract the names of the probability columns\n",
    "    df[time_column] = df[time_column].astype(int)  # Convert time values to integers\n",
    "    full_time_range = range(df[time_column].min(), df[time_column].max() + 1)  # Generate the full range of time steps\n",
    "    df_reindexed = df.set_index(time_column).reindex(full_time_range).reset_index()  # Reindex the DataFrame to fill missing time steps\n",
    "    df_reindexed[probability_columns] = df_reindexed[probability_columns].interpolate()  # Interpolate missing probability values\n",
    "    return df_reindexed  # Return the reindexed DataFrame\n",
    "\n",
    "def lcr(df, k=1):\n",
    "    probabilities = df.iloc[:, 1:].values  # Exclude the 'Time' column for calculations\n",
    "    strengths = np.exp(k * probabilities)\n",
    "\n",
    "    # Sum strengths per row\n",
    "    sum_strengths = strengths.sum(axis=1)\n",
    "\n",
    "    # Compute Luce choice probabilities\n",
    "    luce_probs = strengths / sum_strengths[:, np.newaxis]\n",
    "    \n",
    "    # Step 2: Compute scaling factor Δ_t for each row\n",
    "    # max(act(t)): maximum activation in the current row\n",
    "    row_max = df.iloc[:, 1:].max(axis=1)\n",
    "    # max(act(overall)): global maximum activation across all rows and all items\n",
    "    global_max = df.iloc[:, 1:].max().max()\n",
    "    delta = row_max / global_max\n",
    "\n",
    "    # Step 3: Compute final fixation probabilities p(R_i) = Δ_t * L_i\n",
    "    # Convert delta to numpy array before reshaping to avoid pandas multi-dimensional indexing error\n",
    "    fixation_probs = luce_probs * delta.values[:, np.newaxis]\n",
    "\n",
    "    transformed_df = df.copy()  # Create a copy of the original DataFrame to store results\n",
    "    transformed_df.iloc[:, 1:] = fixation_probs  # Replace the original probabilities with the fixation probabilities\n",
    "    return transformed_df\n",
    "\n",
    "# Define a function to read a CSV file, preprocess data, and apply optional transformations\n",
    "def read_csv(file_path, shift=False, apply_softmax=False, tmult=1, C=5, k=1, \n",
    "             generate_cross=True, apply_lcr_first=False, apply_lcr=False, \n",
    "             normalize=False, rescale=False, rescale_first=False, do_interpolate_missing_time_steps=True,\n",
    "             bgate=False, bthresh=0.01, tmax=1000, sum_weight=1):\n",
    "    df = pd.read_csv(file_path)  # Read the CSV file into a DataFrame\n",
    "    probability_columns = df.columns[1:]  # Extract the names of the probability columns\n",
    "\n",
    "    if bgate:  # Apply bgate logic if bgate is True\n",
    "        # print(f'Applying bgate with threshold {threshold}')\n",
    "        row_sums = df[probability_columns].sum(axis=1)  # Sum probabilities across columns for each row\n",
    "        mask = row_sums < bthresh  # Identify rows where the sum of probabilities is below the threshold\n",
    "        df.loc[mask, probability_columns] = 0  # Set probabilities to 0 for those rows\n",
    "    \n",
    "    if rescale_first:  # Apply rescaling if rescale is True\n",
    "        print('Rescaling data first')\n",
    "        df_min = df[probability_columns].min().min()  # Find the minimum value across all columns\n",
    "        df_max = df[probability_columns].max().max()  # Find the maximum value across all columns\n",
    "        df[probability_columns] = (df[probability_columns] - df_min) / (df_max - df_min)  # Rescale to [0, 1]\n",
    "\n",
    "    if apply_lcr_first:  # Apply Luce choice rule if apply_lcr is True\n",
    "        print(f'Applying lcr FIRST, k = {k}')\n",
    "        print('BEFORE')\n",
    "        print(df.tail(5))\n",
    "        df = lcr(df, k=k)  # Apply LCR to the DataFrame, including only columns in the input\n",
    "        print(f'AFTER')\n",
    "        print(df.tail(5))\n",
    "        print(df.head(5))\n",
    "        \n",
    "    if 'Cross' not in df.columns:  # If the 'Cross' column is missing\n",
    "        sum_columns = ['Target', 'Cohort', 'Rhyme', 'Unrelated']  # Define columns for summation\n",
    "        sum_columns = [col for col in sum_columns if col in df.columns]  # Filter out columns that are not in the set\n",
    "        \n",
    "        if generate_cross:  # If generate_cross is true\n",
    "            total_sum = df[sum_columns].sum(axis=1)  # Calculate the total sum of probabilities for each row\n",
    "            trg_max = df['Target'].max()  # Find the maximum value in the 'Target' column\n",
    "            sum_max = total_sum.max() * sum_weight # Find the maximum value in the 'Target' column\n",
    "            max_value = sum_max\n",
    "            if rescale:\n",
    "                max_value = 1\n",
    "\n",
    "            df['Cross'] = max_value - (total_sum / sum_max)  # Scale it to decrease gradually\n",
    "            df['Cross'] = df['Cross'].clip(lower=0)  # Clip the 'Cross' values to avoid negative values\n",
    "            # # After generating or computing the 'Cross' column, add this code to ensure 'Cross' stays 0 after hitting zero\n",
    "            cross_zero_mask = df['Cross'].eq(0)  # Identify where 'Cross' reaches zero\n",
    "            df['Cross'] = df['Cross'].mask(cross_zero_mask.cumsum().gt(0), 0)  # Set 'Cross' to 0 for the rest of the timesteps\n",
    "        else:  # If generate_cross is false\n",
    "            df['Cross'] = np.nan  # Set the 'Cross' column to NaN values\n",
    "\n",
    "    if rescale:  # Apply rescaling if rescale is True\n",
    "        print('Rescaling data')\n",
    "        df_min = df[probability_columns].min().min()  # Find the minimum value across all columns\n",
    "        df_max = df[probability_columns].max().max()  # Find the maximum value across all columns\n",
    "        df[probability_columns] = (df[probability_columns] - df_min) / (df_max - df_min)  # Rescale to [0, 1]\n",
    "\n",
    "    df['Time'] = df['Time'] * tmult  # Multiply the time column by tmult factor\n",
    "    if do_interpolate_missing_time_steps:  # If interpolation is enabled\n",
    "        print('Interpolating missing time steps')\n",
    "        df = interpolate_missing_time_steps(df)  # Interpolate missing time steps\n",
    "        # input_df = df.copy(deep=True)  # Create a deep copy of the DataFrame\n",
    "\n",
    "    if apply_lcr:  # Apply Luce choice rule if apply_lcr is True\n",
    "        print(f'Applying lcr, k={k}')\n",
    "        df = lcr(df, k=k)  # Apply LCR to the DataFrame, including columns in the input AND cross if it's been added\n",
    "\n",
    "    if normalize:  # Apply normalization if normalize is True\n",
    "        row_sums = df[probability_columns].sum(axis=1)  # Get the sum for each row\n",
    "        non_zero_mask = df[probability_columns] != 0  # Create a mask where the values are non-zero\n",
    "        df[probability_columns] = df[probability_columns].where(~non_zero_mask, df[probability_columns].div(row_sums, axis=0))  # Normalize only non-zero values\n",
    "    \n",
    "    if apply_softmax:  # If softmax is enabled\n",
    "        df = softmax(df[probability_columns].values, axis=1)  # Apply standard softmax transformation\n",
    "    \n",
    "    # Trim the DataFrame to only include rows where 'Time' is less than or equal to tmax\n",
    "    df = df[df['Time'] <= tmax]\n",
    "\n",
    "    return df  # Return transformed DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "381514a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(human_df, comp_df, modelname):\n",
    "    \"\"\"\n",
    "    Calculates objective metrics (RMSE, MAE, Correlation) to measure the difference \n",
    "    between human and simulated fixation proportions.\n",
    "    \"\"\"\n",
    "    item_types = [\"Target\", \"Cohort\", \"Rhyme\", \"Unrelated\", \"Cross\"]\n",
    "    \n",
    "    # Align dataframes by length\n",
    "    min_len = min(len(human_df), len(comp_df))\n",
    "    h_df = human_df.iloc[:min_len].reset_index(drop=True)\n",
    "    c_df = comp_df.iloc[:min_len].reset_index(drop=True)\n",
    "    \n",
    "    metrics = {}\n",
    "    print(f\"\\n{'='*20} {modelname} Objective Metrics {'='*20}\")\n",
    "    print(f\"{'Item':<12} | {'RMSE':<10} | {'MAE':<10} | {'Correlation':<10}\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    total_sq_error = 0\n",
    "    total_abs_error = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    for item in item_types:\n",
    "        if item in h_df.columns and item in c_df.columns:\n",
    "            y_true = h_df[item]\n",
    "            y_pred = c_df[item]\n",
    "            \n",
    "            # RMSE\n",
    "            mse = np.mean((y_true - y_pred)**2)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            # MAE\n",
    "            mae = np.mean(np.abs(y_true - y_pred))\n",
    "            \n",
    "            # Correlation\n",
    "            if y_true.std() == 0 or y_pred.std() == 0:\n",
    "                corr = 0\n",
    "            else:\n",
    "                corr = np.corrcoef(y_true, y_pred)[0, 1]\n",
    "                \n",
    "            metrics[item] = {'RMSE': rmse, 'MAE': mae, 'Correlation': corr}\n",
    "            print(f\"{item:<12} | {rmse:.4f}     | {mae:.4f}     | {corr:.4f}\")\n",
    "            \n",
    "            total_sq_error += np.sum((y_true - y_pred)**2)\n",
    "            total_abs_error += np.sum(np.abs(y_true - y_pred))\n",
    "            total_count += len(y_true)\n",
    "            \n",
    "    # Global weighted metrics\n",
    "    if total_count > 0:\n",
    "        global_rmse = np.sqrt(total_sq_error / total_count)\n",
    "        global_mae = total_abs_error / total_count\n",
    "        print(\"-\" * 55)\n",
    "        print(f\"{'Overall':<12} | {global_rmse:.4f}     | {global_mae:.4f}     | {'-':<10}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "    return metrics\n",
    "\n",
    "def plot_fixation_proportions(human_df, comp_df, modelname, symbol_interval=25):\n",
    "    markers = {\"Target\": \"o\", \"Cohort\": \"s\", \"Rhyme\": \"^\", \"Unrelated\": \".\", \"Cross\": \"x\"}  # Define markers for different item types\n",
    "    item_types = [\"Target\", \"Cohort\", \"Rhyme\", \"Unrelated\", \"Cross\"]  # List of item types\n",
    "\n",
    "    # Define custom font sizes\n",
    "    title_fontsize = 24\n",
    "    axis_label_fontsize = 22\n",
    "    tick_labelsize = 18\n",
    "    legend_fontsize = 18\n",
    "    annotate_fontsize = 32\n",
    "    \n",
    "    # Ensure both dataframes cover the same time range for comparison\n",
    "    # We assume 'Time' is available or the index represents time. \n",
    "    # Based on read_csv, 'Time' is a column but indices are reset.\n",
    "    # Let's align them based on the minimum common length to simply truncate the longer one,\n",
    "    # or better, align by their 'Time' column if possible.\n",
    "    \n",
    "    # Assuming standard index alignment (0, 1, 2...) if they start at same relative time:\n",
    "    min_len = min(len(human_df), len(comp_df))\n",
    "    human_df_clipped = human_df.iloc[:min_len]\n",
    "    comp_df_clipped = comp_df.iloc[:min_len]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20, 12))\n",
    "    for item in item_types:\n",
    "        if item in human_df_clipped.columns and item in comp_df_clipped.columns:\n",
    "            difference = human_df_clipped[item] - comp_df_clipped[item]\n",
    "            # Use the time column if available for x-axis, else use index\n",
    "            if 'Time' in human_df_clipped.columns:\n",
    "                x_axis = human_df_clipped['Time']\n",
    "            else:\n",
    "                x_axis = human_df_clipped.index\n",
    "                \n",
    "            ax.plot(x_axis, difference, label=item, marker=markers.get(item, ''), markevery=symbol_interval)\n",
    "\n",
    "    ax.set_title('Differences (human - simulated)', fontsize=title_fontsize)\n",
    "    ax.set_xlabel('Time step', fontsize=axis_label_fontsize)\n",
    "    ax.set_ylabel('Fixation proportion difference', fontsize=axis_label_fontsize)\n",
    "    ax.tick_params(axis='both', labelsize=tick_labelsize)  # Set tick label size\n",
    "    ax.legend(fontsize=legend_fontsize)\n",
    "    ax.set_ylim(-1, 1)\n",
    "    fig.suptitle(f'Differences (human - simulated) for {modelname}', fontsize=title_fontsize)\n",
    "    fig.savefig(f'DIFF/differences_{modelname}.png')\n",
    "    \n",
    "    # show human df and comp df  \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(20, 24))\n",
    "    axes[0].set_title('Human Data', fontsize=title_fontsize)\n",
    "    axes[1].set_title('Simulated Data', fontsize=title_fontsize)\n",
    "    for item in item_types:\n",
    "        if item in human_df_clipped.columns:\n",
    "            axes[0].plot(human_df_clipped['Time'], human_df_clipped[item], label=item, marker=markers.get(item, ''), markevery=symbol_interval)\n",
    "        if item in comp_df_clipped.columns:\n",
    "            # axes[1].axvline(x=480, color='gray', linestyle='--', alpha=0.5, label=\"theoratical earliest RT\")  # Add vertical line at the start of the time range\n",
    "            axes[1].plot(comp_df_clipped['Time'], comp_df_clipped[item], label=item, marker=markers.get(item, ''), markevery=symbol_interval)\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel('Time step', fontsize=axis_label_fontsize)\n",
    "        ax.set_ylabel('Fixation proportion', fontsize=axis_label_fontsize)\n",
    "        ax.tick_params(axis='both', labelsize=tick_labelsize)  # Set tick label size\n",
    "        ax.legend(fontsize=legend_fontsize)\n",
    "    fig.savefig(f'OUT/fixation_proportions_{modelname}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "858d5f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding /home/fie24002/earshot_nn to sys.path\n",
      "Interpolating missing time steps\n",
      "Processing csv: experiments/en_words_ku_baseline/Baseline/training/competition_mean.csv\n",
      "Interpolating missing time steps\n",
      "\n",
      "==================== baseline Objective Metrics ====================\n",
      "Item         | RMSE       | MAE        | Correlation\n",
      "-------------------------------------------------------\n",
      "Target       | 0.1287     | 0.1018     | 0.9367\n",
      "Cohort       | 0.0437     | 0.0342     | 0.7735\n",
      "Rhyme        | 0.0459     | 0.0369     | 0.6009\n",
      "Unrelated    | 0.0161     | 0.0109     | -0.5328\n",
      "Cross        | 0.1283     | 0.1015     | 0.9774\n",
      "-------------------------------------------------------\n",
      "Overall      | 0.0864     | 0.0570     | -         \n",
      "============================================================\n",
      "\n",
      "Processing csv: experiments/en_words_ku_causal_cnn/causal-cnn/training/competition_mean.csv\n",
      "Interpolating missing time steps\n",
      "\n",
      "==================== causal-cnn Objective Metrics ====================\n",
      "Item         | RMSE       | MAE        | Correlation\n",
      "-------------------------------------------------------\n",
      "Target       | 0.1566     | 0.1234     | 0.9087\n",
      "Cohort       | 0.0533     | 0.0445     | 0.6503\n",
      "Rhyme        | 0.0704     | 0.0575     | 0.6235\n",
      "Cross        | 0.1274     | 0.1034     | 0.9660\n",
      "-------------------------------------------------------\n",
      "Overall      | 0.1102     | 0.0822     | -         \n",
      "============================================================\n",
      "\n",
      "Processing csv: experiments/en_words_ku_causal_trans/causal-trans/training/competition_mean.csv\n",
      "Interpolating missing time steps\n",
      "\n",
      "==================== causal-trans Objective Metrics ====================\n",
      "Item         | RMSE       | MAE        | Correlation\n",
      "-------------------------------------------------------\n",
      "Target       | 0.1329     | 0.1063     | 0.9373\n",
      "Cohort       | 0.0454     | 0.0390     | 0.7204\n",
      "Rhyme        | 0.0866     | 0.0658     | 0.5669\n",
      "Unrelated    | 0.0199     | 0.0165     | -0.5282\n",
      "Cross        | 0.0680     | 0.0578     | 0.9840\n",
      "-------------------------------------------------------\n",
      "Overall      | 0.0803     | 0.0571     | -         \n",
      "============================================================\n",
      "\n",
      "Processing csv: experiments/en_words_ku_causal_rcnn/causal-rcnn/training/competition_mean.csv\n",
      "Interpolating missing time steps\n",
      "\n",
      "==================== causal-rcnn Objective Metrics ====================\n",
      "Item         | RMSE       | MAE        | Correlation\n",
      "-------------------------------------------------------\n",
      "Target       | 0.1427     | 0.1102     | 0.9295\n",
      "Cohort       | 0.0443     | 0.0350     | 0.7399\n",
      "Rhyme        | 0.0474     | 0.0321     | 0.6201\n",
      "Unrelated    | 0.0163     | 0.0117     | -0.5592\n",
      "Cross        | 0.0953     | 0.0731     | 0.9749\n",
      "-------------------------------------------------------\n",
      "Overall      | 0.0824     | 0.0524     | -         \n",
      "============================================================\n",
      "\n",
      "Processing csv: experiments/en_words_ku_causal_2lstm/causal-2LSTM/training/competition_mean.csv\n",
      "Interpolating missing time steps\n",
      "\n",
      "==================== causal-2lstm Objective Metrics ====================\n",
      "Item         | RMSE       | MAE        | Correlation\n",
      "-------------------------------------------------------\n",
      "Target       | 0.1305     | 0.0989     | 0.9442\n",
      "Cohort       | 0.0434     | 0.0345     | 0.7688\n",
      "Rhyme        | 0.0750     | 0.0593     | 0.6306\n",
      "Unrelated    | 0.0164     | 0.0115     | -0.0316\n",
      "Cross        | 0.0981     | 0.0853     | 0.9844\n",
      "-------------------------------------------------------\n",
      "Overall      | 0.0830     | 0.0579     | -         \n",
      "============================================================\n",
      "\n",
      "Processing csv: experiments/en_words_ku_2lstmbi/noncausal-2LSTM/training/competition_mean.csv\n",
      "Interpolating missing time steps\n",
      "\n",
      "==================== noncausal-2lstm Objective Metrics ====================\n",
      "Item         | RMSE       | MAE        | Correlation\n",
      "-------------------------------------------------------\n",
      "Target       | 0.3487     | 0.3027     | 0.7470\n",
      "Cohort       | 0.0705     | 0.0532     | 0.5872\n",
      "Rhyme        | 0.0981     | 0.0944     | 0.7373\n",
      "Unrelated    | 0.0161     | 0.0107     | -0.2742\n",
      "Cross        | 0.3736     | 0.3048     | 0.8441\n",
      "-------------------------------------------------------\n",
      "Overall      | 0.2349     | 0.1532     | -         \n",
      "============================================================\n",
      "\n",
      "Processing csv: experiments/en_words_ku_rcnn/noncausal-rcnn/training/competition_mean.csv\n",
      "Interpolating missing time steps\n",
      "\n",
      "==================== noncausal-rcnn Objective Metrics ====================\n",
      "Item         | RMSE       | MAE        | Correlation\n",
      "-------------------------------------------------------\n",
      "Target       | 0.1989     | 0.1551     | 0.8704\n",
      "Cohort       | 0.0561     | 0.0414     | 0.5660\n",
      "Rhyme        | 0.0759     | 0.0665     | 0.6829\n",
      "Unrelated    | 0.0162     | 0.0117     | -0.4396\n",
      "Cross        | 0.1513     | 0.1116     | 0.9465\n",
      "-------------------------------------------------------\n",
      "Overall      | 0.1197     | 0.0773     | -         \n",
      "============================================================\n",
      "\n",
      "Processing csv: experiments/en_words_ku_cnn/noncausal-cnn/training/competition_mean.csv\n",
      "Interpolating missing time steps\n",
      "\n",
      "==================== noncausal-cnn Objective Metrics ====================\n",
      "Item         | RMSE       | MAE        | Correlation\n",
      "-------------------------------------------------------\n",
      "Target       | 0.3088     | 0.2444     | 0.6747\n",
      "Cohort       | 0.0739     | 0.0553     | 0.5055\n",
      "Rhyme        | 0.0431     | 0.0324     | 0.6609\n",
      "Cross        | 0.3077     | 0.2328     | 0.8491\n",
      "-------------------------------------------------------\n",
      "Overall      | 0.2221     | 0.1412     | -         \n",
      "============================================================\n",
      "\n",
      "Processing csv: experiments/en_words_ku_trans/noncausal-trans/training/competition_mean.csv\n",
      "Interpolating missing time steps\n",
      "\n",
      "==================== noncausal-trans Objective Metrics ====================\n",
      "Item         | RMSE       | MAE        | Correlation\n",
      "-------------------------------------------------------\n",
      "Target       | 0.4456     | 0.3788     | 0.8123\n",
      "Cohort       | 0.0721     | 0.0561     | 0.7676\n",
      "Rhyme        | 0.0861     | 0.0810     | 0.6943\n",
      "Unrelated    | 0.0159     | 0.0101     | 0.4871\n",
      "Cross        | 0.4357     | 0.3354     | 0.8943\n",
      "-------------------------------------------------------\n",
      "Overall      | 0.2833     | 0.1723     | -         \n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Check if we are in the 'notebooks' directory and define project root accordingly\n",
    "if os.path.basename(current_dir) == 'notebooks':\n",
    "    project_root = os.path.dirname(current_dir)\n",
    "else:\n",
    "    # Assume we are already at the project root or handle other structures as needed\n",
    "    project_root = current_dir\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    print(f\"Adding {project_root} to sys.path\")\n",
    "    sys.path.append(project_root)\n",
    "    \n",
    "model2res = {\n",
    "    # Causal Models from train.sh\n",
    "    \"baseline\": \"experiments/en_words_ku_baseline/Baseline/training/competition_mean.csv\",\n",
    "    \"causal-cnn\": \"experiments/en_words_ku_causal_cnn/causal-cnn/training/competition_mean.csv\",\n",
    "    \"causal-trans\": \"experiments/en_words_ku_causal_trans/causal-trans/training/competition_mean.csv\",\n",
    "    \"causal-rcnn\": \"experiments/en_words_ku_causal_rcnn/causal-rcnn/training/competition_mean.csv\",\n",
    "    \"causal-2lstm\": \"experiments/en_words_ku_causal_2lstm/causal-2LSTM/training/competition_mean.csv\",\n",
    "    # \"causal-ctrans\": \"experiments/en_words_ku_causal_convtrans/causal-convtrans/training/competition_mean.csv\",\n",
    "\n",
    "    # Non-Causal Models from train.sh\n",
    "    \"noncausal-2lstm\": \"experiments/en_words_ku_2lstmbi/noncausal-2LSTM/training/competition_mean.csv\",\n",
    "    # \"noncausal-convtrans\": \"experiments/en_words_ku_convtrans/noncausal-convtrans/training/competition_mean.csv\",\n",
    "    \"noncausal-rcnn\": \"experiments/en_words_ku_rcnn/noncausal-rcnn/training/competition_mean.csv\",\n",
    "    \"noncausal-cnn\": \"experiments/en_words_ku_cnn/noncausal-cnn/training/competition_mean.csv\",\n",
    "    \"noncausal-trans\": \"experiments/en_words_ku_trans/noncausal-trans/training/competition_mean.csv\"\n",
    "}\n",
    "input_path = os.path.join(project_root, \"notebooks/INPUT/amt_human_mean.csv\")\n",
    "human_df = read_csv(input_path, normalize=False, rescale=False, tmult=1, \n",
    "                    apply_lcr_first=False, apply_lcr=False, k=1, bgate=False, bthresh=0.01, tmax=1000)\n",
    "    \n",
    "for modelname, csv_path in model2res.items():\n",
    "    print(f\"Processing csv: {csv_path}\")\n",
    "    # Construct absolute path to ensure we find the file regardless of CWD\n",
    "    full_csv_path = os.path.join(project_root, csv_path)\n",
    " \n",
    "    comp_df = read_csv(full_csv_path, normalize=False, rescale=False, tmult=10, \n",
    "                    apply_lcr_first=False, apply_lcr=False, k=1, bgate=False, bthresh=0.01, tmax=1000)\n",
    "\n",
    "    # plot_fixation_proportions(\n",
    "    #     human_df,  # \"INPUT/amt_human_mean.csv\"\n",
    "    #     comp_df, # underlying response probabilities\n",
    "    #     modelname\n",
    "    # )\n",
    "\n",
    "    # Calculate and print objective metrics\n",
    "    metrics = calculate_metrics(human_df, comp_df, modelname) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
